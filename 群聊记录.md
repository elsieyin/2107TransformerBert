以下回答基本都来自可可爱爱助教致Great

#### slot切片排序

ria：![image-20210730161953815](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730161953815.png)

这个地方相当于是按照slots切片排序，这个属于Python的sort多级排序，给你看个例子![image-20210730162023518](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730162023518.png)
slot_voab重新排下序，然后首选按照slot_vocab每个元素的[2:]排序，如果[2:]相同的话就按照元素的[:2]部分排序



麦克阿瑟：![image-20210730162057591](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730162057591.png)

loss = loss / self.args.gradient_accumulation_steps，请问这句话是不是应该写在那底下啊，应该在step的时候再去平均吧？
不是，就是在外边求，在step那一步是累积梯度求导的，外边这个是对loss进行标准化。
每累积一次都要除嘛？不应该累积gradient_accumulation_steps次才除以它嘛，为什么1每累积一次就除以.gradient_accumulation_steps啊？
不是，这里累积指的是梯度累积，loss的话直接平均就可以，其实这里loss不做平均也可以，这里可以稍微改写下。
那应该怎么改啊，每一次都除的话，也会影响梯度啊
![image-20210730162314557](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730162314557.png)

改成这样的，loss不用平均，因为loss没有累加，还是直接从model(**inputs)算出来的.https://gist.github.com/thomwolf/ac7a7da6b1888c2eeac8ac8b9b05d3d3#file-gradient_accumulation-py

```python
model.zero_grad()                                   # Reset gradients tensors
for i, (inputs, labels) in enumerate(training_set):
    predictions = model(inputs)                     # Forward pass
    loss = loss_function(predictions, labels)       # Compute loss function
    loss = loss / accumulation_steps                # Normalize our loss (if averaged)
    loss.backward()                                 # Backward pass
    if (i+1) % accumulation_steps == 0:             # Wait for several backward steps
        optimizer.step()                            # Now we can do an optimizer step
        model.zero_grad()                           # Reset gradients tensors
        if (i+1) % evaluation_steps == 0:           # Evaluate the model when we...
            evaluate_model()                        # ...have no gradients accumulated
@muaz-git

```

我大概理解啦。。。也就是只要不zero操作，每一次计算loss的时候，之前计算的也会累积到。。也就是计算第n次loss的时候，求backward的时候会计算出1到n的梯度，是这个意思嘛？
对的![image-20210730162449277](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730162449277.png)

![image-20210730162458524](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730162458524.png)

你看这个pytorch的例子就明白了

永三尺：<img src="C:/Users/86182/AppData/Roaming/Typora/typora-user-images/image-20210730155041699.png" alt="image-20210730155041699" style="zoom: 67%;" />

![image-20210730155046494](C:/Users/86182/AppData/Roaming/Typora/typora-user-images/image-20210730155046494.png)

![image-20210730155054132](C:/Users/86182/AppData/Roaming/Typora/typora-user-images/image-20210730155054132.png)

请问这里构建token_type_ids时，全部都是用0来建模，最后的embedding也都是0，那这个token_type_ids有什么意义啊？
是否是第二句话，针对text pari任务而言的，这里每个样本输入只有一个text，所以token type ids都是0，代表所有token都是来自一句话。
如果样本只有一句话，那这个操作也是必须的吗？
不管是一句话还是两句话都是需要的，模型的输入包括两个输入，一个tokenids 一个是token_typeids。
那 position_embedding为什么可以没有啊？
这个不需要，这个是模型的权重参数，不是输入。

麦克阿瑟：bert里1个单词还能拆成多份嘛？这个依照什么规律拆啊？
![image-20210730155509706](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730155509706.png)

WordPiece分词，可以产生subword
把中文的ner用bert会出现这种情况嘛？
不会，中文的字都是单个粒度，英文的一个字是多个字母。
咱们课上讲的关系抽取代码，只能一句话抽取一个三元组嘛？
是的，多句话可以分完句提取。

Nicholas-kai：bert模型的多头是一起训练还是一个个训练？
一起训练的。

左玉辉： pytorch半精度下 想重复反向传播，怎么设置retrain？使用fp16了 想加对抗训练 但是需要多次backward，amp.scale_loss 也是有 retain_graph的



Oliver：这一句为啥多一个.![image-20210730155827496](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730155827496.png)是相对路径导入的意思吗？
对的，当前路路径下有个module
报错没找到包ImportError: attempted relative import with no known parent package，我这里是有包的。![image-20210730155953280](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730155953280.png)
嗯嗯应该是路径有问题了，要不你改写成绝对路径，或者添加到sys.path.append('xxx/model')，from model.module import xxx
 No module named 'model'，可以了 
嗯嗯，执行入口文件也会影响。
这个改成model父级目录地址就好啦。
执行入口文件是啥？
就是你你运行的哪个文件，最好import的时候把路径写完整，比如首先确定好项目的目录，然后import的时候如果报错找不到的话，就把添加sys.path.append('项目目录/导入包的上级目录')
![image-20210730160218370](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730160218370.png)
https://blog.csdn.net/liudinglong1989/article/details/104468495

#### 用args参数怎么debug？

args参数要命令行输入
https://blog.csdn.net/counte_rking/article/details/78837028
，使用Pycharm给Python程序传递参数![image-20210730160334813](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730160334813.png)

为什么每一层都要添加两个parameter？
![image-20210730163118777](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163118777.png)
weight_decay为0.0的时候 两个parameter都是相同的？
Michael老师：没有区分的话，可以只分一组
如果设置了L2，还需要weight_decay为0.0的parameter吗？
这个weght decay就是L2。

柳杰：在main.py里run会出现OSError: Model name './bert_finetune_ner/resources/uncased_L-2_H-128_A-2' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). We assumed './bert_finetune_ner/resources/uncased_L-2_H-128_A-2' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.
如果直接在命令行就没问题，是我个例吗？
这路径不存在吗？你要不写绝对路径。
存在，嗯呢。

#### [-100]

Oliver：![image-20210730163341239](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163341239.png)
我debug出现这个错误，正常运行则不出现，网上的方法试过也不行，会是什么问题？

```python
 import os
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"
```

你加上这两句话，看看可以调试不
试过了 不行。而且是用了crf才有问题 不用debug没问题
![image-20210730163508487](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163508487.png)
我查了下应该是标签越界的问题，你看看是不是标签有越界的，![image-20210730163531330](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163531330.png)
你可以用cpu跑一下，我之前也是通过这个方式：cpu运行可以提示那里索引越界。
我刚刚查过标签 我再试试！我这也没多呀![image-20210730163557646](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163557646.png)

标签数，要查哪里的标签？
![image-20210730163647022](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163647022.png)

你这个方式尝试了吗？你把gpu禁用了，然后debug试试，看看有没有报出具体的错误。
是越界了，但是我找不到，![image-20210730163713845](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163713845.png)
这个-100，你检查下是否在输入的x里面或者y，应该有的
tokenizer出来的x与y吗？
对的。你现在直接用cpu运行呢，别debug，看看能定位出错误码。

```python
IndexError: index -100 is out of bounds for dimension 0 with size 39
```

没有定位出。
“ 0 with size 39”这个应该是40个标签吧？
![image-20210730163844223](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163844223.png)
所以问题出现在了y里面
![image-20210730163904599](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163904599.png)

已经给出了，你看看你的y是不是里面有-100这个索引，你可以遍历下数据，检查下。
有 pad这些是-100。
你检查下y里面有吗？
有-100。![image-20210730163940429](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730163940429.png)

我查过tokenizer输出的input_ids与label，维度都是(batch_size, max_len)
![image-20210730165427301](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165427301.png)
logits维度是[B, L, num_labels]，这样有问题吗？
没有问题这样，你昨天不是说你的tags里面有-100吗？你看看是不是你数据处理的问题，怎么可能有-100这个数字。
pad、cls这些应该用什么？label id，M老师之前的代码就是用-100的 我跑通了没问题。
文本里面出现是可以的，就是label不应该出现吧。
我试试把这些改成0。。。额，真的是！现在跑通了。但是很奇怪 M老师的原代码-100就可以



永三尺：助教，我用tokenizer.encode_plus，假如我输入的句子是两个句子t1，t2拼接之后的，那我的token_type_ids应该怎么设置啊？我在做拼接的时候 t1 + ‘[SEP]’ + t2。如果设置return_token_type_ids=True ， 如果设置return_token_type_ids=True ，好像会把 t1 + ‘[SEP]’ + t2 看成是一个句子？
别输入两个拼接的，可以接受两个参数。可以接受两个参数，如果非得拼接输入的话，你可以重新对tokentypeids赋值，根据sep这个符号，前面的都是0，后面都是1。
那如果是三个句子呢，一个cls 两个sep，这种只能重新赋值了吗？
对的，三个句子，也得处理成两个句子吧，只能接受两种类型的token type，0和1。
bert只能接受两种0和1两种token_type_id吗？
你试下 0 1 2可以吗？我之前没有尝试过，但是感觉会超出token type的索引，他预训练的时候用的nsp任务。
有道理啊，![image-20210730164258340](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164258340.png)

我如果手动设置 这里 add_special_token 和 return_token_type_ids，应该怎么填呢？
![image-20210730164317675](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164317675.png)

add_special_tokens 是bool类型的。
![image-20210730164330044](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164330044.png)

return_token_type_ids 这个也是，不能设置特殊的token。

imoprtance*：![image-20210730164356683](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164356683.png)

助教大大，这个错误是什么原因？把focal loss设置为true，就报了这个错误。
![image-20210730164729889](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164729889.png)

focal loss没有自动求导的，focal loss是不是没有继承torch.nn，https://github.com/yatengLG/Focal-Loss-Pytorch，你看看这个例子是不是缺少一些东西



吴新刚：![image-20210730164918977](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164918977.png)第一次复现，报这个错，怎么解决？
你数据是不是构建的有问题？你检查下你的数据![image-20210730164954287](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730164954287.png)

你下面的错误是什么？
![image-20210730165011441](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165011441.png)

![image-20210730165015946](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165015946.png)

```python
OSError: Model name './bert_finetune_ner/resources/uncased_L-2_H-128_A-2' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). We assumed './bert_finetune_ner/resources/uncased_L-2_H-128_A-2' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.
```

你看下这路径有吗，没有的话，写绝对路径，查了一下，说没有'vocab.txt'；但我确实是有此文件的。执行参数中，似乎又没看到定义'uncased_L-2_H-128_A-2'的地方
就比如他在你路径下的D盘某个文件夹，比如D：/bert_finetune_ner/resources/
然后呢？如何定义该文件夹？
![image-20210730165205615](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165205615.png)

类似这样，你写完整就可以了。
![image-20210730165222766](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165222766.png)
utils.py文件的这里 添加绝对路径

永三尺：![image-20210730165845101](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165845101.png)
 助教，我最近在做多轮对话的任务，我现在把前三句话做了拼接和embedding，但是我的label应该怎么处理啊？任务是生成 query-02-rewrite，难道我要用规则去打标？
你想要做什么处理？现在label有了，
就是，我现在query-02-rewrite还没有做处理，我想是不是要把query-02-rewrite做序列标注出实体？![image-20210730165930215](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165930215.png)
<img src="%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730165942508.png" alt="image-20210730165942508" style="zoom:67%;" />

这是我现在的input里的东西 label这里我不太懂怎写。
你跑的模型是生成式模型吧，所以这里你写成query-02-rewrite，这个就可以
我用的最基础的bert，我再琢磨琢磨这个流程，我这个好像也不是生成式任务，其实是指代消解

Trouble_Slayer：![image-20210730170054732](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170054732.png)

这个问题啥情况啊？
![image-20210730170107732](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170107732.png)

你看下是不是内存不足，你重启下notebook或者减小batch size试下
但我这个报错和你发的那个不一样呢
![image-20210730170130506](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170130506.png)

![image-20210730170136538](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170136538.png)
https://blog.csdn.net/li_jiaoyang/article/details/116047462
你看下是不是这个，减小下bs试试
![image-20210730170204244](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170204244.png)
好像大多是cuda版本不一致，你可以检查下你的torch可以用gpu吗?
可以用gpu。
那估计是内存不足。
我6g用的roberta 会不足吗？我记得以前显存不足报的是out of mem的错啊，跟这次不一样，我用的中文roberta base。
你减小bs试试，先重启notebook，然后减小bs。
bs已经是2了。
设置成1，试试。
(我：总之这位同学好像还是显卡驱动，torch，cuda版本不匹配的问题，好懒的整理55.)
https://pytorch.org/get-started/previous-versions/
晨曦：能安装什么版本的cuda，是由显卡驱动决定的
![image-20210730170637178](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170637178.png)
我的显卡驱动支持cuda 11.2,我安装的也是11.2，但torch1.9+cuda111，torchvion好像11.3，你都弄到你的显卡支持的最新试试。我的基本是最新没有问题，torch上写的只支持到11.1，但实际上跑11.2是没有问题的。
![image-20210730170718168](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170718168.png)
助教：嗯嗯是的，要看下这两个是否兼容

#### 怎么看显卡和cuda版本是否兼容

https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html
![image-20210730170806905](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730170806905.png)

到这里这位同学发现了他的显卡驱动才445 和11.0不兼容，准备升级驱动试试

永三尺：助教，如果是ner任务，我的bert输入是文本和标注好的序列，那我输出的维度应该设置成什么？ 🤔
@永沢 输出的维度是你序列标签类别的个数
那如果我的标注序列是 000100000200 ， bert的输出维度应该是3？
对的 
[0，1，2］
0 1 2，只有这三个标签吧
![image-20210730171027213](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730171027213.png)

这是我想实现的过程 如果只有一个实体序列里就是1 两个实体就是1 2
其他样本也有0吧，得设置全局的label总数，还是3，否则遇到label等于0的时候label个数对不上。
那我这样设置之后 output的维度应该是什么？
比如一条样本的话，样本长度为10，3个tag种类，（1，10，3)
batch_size ， max_len，label_size么？是不是这个样子？
<img src="%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730171117684.png" alt="image-20210730171117684" style="zoom:67%;" />

对的，每个token对应不同tag的概率。
![image-20210730171143184](%E7%BE%A4%E8%81%8A%E8%AE%B0%E5%BD%95.assets/image-20210730171143184.png)
但我模型如果这样写的话，它的输出大小不还是label_size吗？怎么变成我想要的那个[batch_size ， max_len，label_size]
你这样是对整个句子做分类，你直接用BertForTokenClassification整个，对每个toekn进行分类。
https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification
还有这个，我去看看！

